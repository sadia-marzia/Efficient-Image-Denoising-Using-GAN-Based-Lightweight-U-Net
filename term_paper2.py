# -*- coding: utf-8 -*-
"""Term Paper2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VAzIkmMbpzqRrzSrWZ7KCzoriexdAZBF

# **Oxford IIIT pet Dataset**

# **Noise 10**
"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.applications import VGG19
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers.schedules import CosineDecayRestarts
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

# ===========================================
# ‚öôÔ∏è SETTINGS
# ===========================================
IMG_SIZE = 128
BATCH_SIZE = 8
EPOCHS = 20
NOISE_STD = 10 / 255.0  # scaled for [0,1]
initial_lr = 2e-4

# ===========================================
# üß† DATA PREPARATION (Oxford-IIIT Pet, 7349 images)
# ===========================================
full_ds = tfds.load('oxford_iiit_pet', split='train+test', with_info=False)


# 80‚Äì10‚Äì10 split
total_count = 7349
train_count = int(0.8 * total_count)
val_count = int(0.1 * total_count)
test_count = total_count - train_count - val_count

train_ds_raw = full_ds.take(train_count)
val_ds_raw = full_ds.skip(train_count).take(val_count)
test_ds_raw = full_ds.skip(train_count + val_count)

def preprocess(example):
    image = tf.image.resize(example['image'], [IMG_SIZE, IMG_SIZE])
    image = tf.cast(image, tf.float32) / 255.0
    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=NOISE_STD)
    noisy = tf.clip_by_value(image + noise, 0.0, 1.0)
    return noisy, image

train_ds = train_ds_raw.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
val_ds = val_ds_raw.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_ds = test_ds_raw.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# ===========================================
# üß± LIGHTWEIGHT U-NET GENERATOR
# ===========================================
def conv_block(x, filters, kernel_size=3):
    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    return x

def build_generator():
    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    c1 = conv_block(inp, 32)
    p1 = layers.MaxPooling2D()(c1)

    c2 = conv_block(p1, 64)
    p2 = layers.MaxPooling2D()(c2)

    c3 = conv_block(p2, 128)

    u2 = layers.UpSampling2D()(c3)
    concat2 = layers.Concatenate()([u2, c2])
    c4 = conv_block(concat2, 64)

    u1 = layers.UpSampling2D()(c4)
    concat1 = layers.Concatenate()([u1, c1])
    c5 = conv_block(concat1, 32)

    out = layers.Conv2D(3, 1, activation='sigmoid')(c5)
    return Model(inp, out, name="Lightweight_UNet_Generator")

# ===========================================
# üß± DISCRIMINATOR
# ===========================================
def build_discriminator():
    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    x = layers.Conv2D(16, 4, strides=2, padding='same')(inp)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(32, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(64, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Flatten()(x)
    out = layers.Dense(1, activation='sigmoid')(x)
    return Model(inp, out, name="Discriminator")

generator = build_generator()
discriminator = build_discriminator()

# ===========================================
# üéØ LOSSES
# ===========================================
vgg = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))
vgg.trainable = False
vgg_model = Model(vgg.input, vgg.get_layer('block3_conv3').output)

def perceptual_loss(y_true, y_pred):
    return tf.reduce_mean(tf.abs(vgg_model(y_true) - vgg_model(y_pred)))

def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

# ===========================================
# ‚öôÔ∏è OPTIMIZERS with Cosine Decay
# ===========================================
lr_schedule = CosineDecayRestarts(
    initial_learning_rate=initial_lr,
    first_decay_steps=5000,
    t_mul=2.0,
    m_mul=0.9,
    alpha=1e-6
)
gen_opt = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.5)
disc_opt = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.5)
bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)

# ===========================================
# üöÄ TRAINING STEP
# ===========================================
@tf.function
def train_step(noisy, clean):
    valid = tf.ones((tf.shape(noisy)[0], 1))
    fake = tf.zeros((tf.shape(noisy)[0], 1))

    with tf.GradientTape(persistent=True) as tape:
        generated = generator(noisy, training=True)
        real_output = discriminator(clean, training=True)
        fake_output = discriminator(generated, training=True)
        disc_loss = (bce(valid, real_output) + bce(fake, fake_output)) * 0.5

        gan_loss = bce(valid, fake_output)
        L1 = tf.reduce_mean(tf.abs(clean - generated))
        VGG_L = perceptual_loss(clean, generated)
        SSIM_L = ssim_loss(clean, generated)
        gen_total_loss = 0.7*L1 + 0.2*VGG_L + 0.1*SSIM_L + 0.001*gan_loss

    grad_gen = tape.gradient(gen_total_loss, generator.trainable_variables)
    grad_disc = tape.gradient(disc_loss, discriminator.trainable_variables)
    gen_opt.apply_gradients(zip(grad_gen, generator.trainable_variables))
    disc_opt.apply_gradients(zip(grad_disc, discriminator.trainable_variables))
    return gen_total_loss, disc_loss

# ===========================================
# üìä METRICS FUNCTION
# ===========================================
def evaluate_model(dataset):
    psnr_total, nmse_total, ssim_total, count = 0, 0, 0, 0
    for noisy, clean in dataset:
        gen = generator.predict(noisy, verbose=0)
        for i in range(len(gen)):
            clean_np = np.clip(clean[i].numpy(), 0, 1)
            gen_np = np.clip(gen[i], 0, 1)
            psnr_val = peak_signal_noise_ratio(clean_np, gen_np, data_range=1.0)
            ssim_val = structural_similarity(clean_np, gen_np, channel_axis=-1, data_range=1.0)
            nmse_val = np.mean((clean_np - gen_np)**2) / np.mean(clean_np**2)
            psnr_total += psnr_val
            ssim_total += ssim_val
            nmse_total += nmse_val
            count += 1
    return psnr_total/count, nmse_total/count, ssim_total/count

# ===========================================
# üèÉ‚Äç‚ôÄÔ∏è MAIN TRAINING LOOP
# ===========================================
for epoch in range(1, EPOCHS+1):
    g_loss_avg, d_loss_avg, batches = 0, 0, 0
    for noisy, clean in train_ds:
        g_loss, d_loss = train_step(noisy, clean)
        g_loss_avg += g_loss
        d_loss_avg += d_loss
        batches += 1
    g_loss_avg /= batches
    d_loss_avg /= batches

    val_psnr, val_nmse, val_ssim = evaluate_model(val_ds)
    print(f"Epoch {epoch}/{EPOCHS}")
    print(f"Gen Loss: {g_loss_avg:.4f}, Disc Loss: {d_loss_avg:.4f}")
    print(f"Validation PSNR: {val_psnr:.4f}, NMSE: {val_nmse:.6f}, SSIM: {val_ssim:.4f}")
    print("-"*60)

# ===========================================
# üß™ FINAL TEST EVALUATION
# ===========================================
test_psnr, test_nmse, test_ssim = evaluate_model(test_ds)
print("\n‚úÖ Final Test Results:")
print(f"PSNR: {test_psnr:.4f}, NMSE: {test_nmse:.6f}, SSIM: {test_ssim:.4f}")

# ===========================================
# üñºÔ∏è VISUALIZATION
# ===========================================
for noisy_imgs, clean_imgs in test_ds.take(1):
    denoised_imgs = generator(noisy_imgs, training=False)
    plt.figure(figsize=(12, 6))
    for i in range(3):
        plt.subplot(3,3,i*3+1)
        plt.title("Noisy")
        plt.imshow(noisy_imgs[i])
        plt.axis('off')
        plt.subplot(3,3,i*3+2)
        plt.title("Denoised")
        plt.imshow(denoised_imgs[i])
        plt.axis('off')
        plt.subplot(3,3,i*3+3)
        plt.title("Original")
        plt.imshow(clean_imgs[i])
        plt.axis('off')
    plt.show()

"""# **Noise 50**"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.applications import VGG19
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers.schedules import CosineDecayRestarts
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

# ===========================================
# ‚öôÔ∏è SETTINGS
# ===========================================
IMG_SIZE = 128
BATCH_SIZE = 8
EPOCHS = 20
NOISE_STD = 50 / 255.0  # scaled for [0,1]
initial_lr = 2e-4

# ===========================================
# üß† DATA PREPARATION (Oxford-IIIT Pet, 7349 images)
# ===========================================
full_ds = tfds.load('oxford_iiit_pet', split='train+test', with_info=False)


# 80‚Äì10‚Äì10 split
total_count = 7349
train_count = int(0.8 * total_count)
val_count = int(0.1 * total_count)
test_count = total_count - train_count - val_count

train_ds_raw = full_ds.take(train_count)
val_ds_raw = full_ds.skip(train_count).take(val_count)
test_ds_raw = full_ds.skip(train_count + val_count)

def preprocess(example):
    image = tf.image.resize(example['image'], [IMG_SIZE, IMG_SIZE])
    image = tf.cast(image, tf.float32) / 255.0
    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=NOISE_STD)
    noisy = tf.clip_by_value(image + noise, 0.0, 1.0)
    return noisy, image

train_ds = train_ds_raw.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
val_ds = val_ds_raw.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_ds = test_ds_raw.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# ===========================================
# üß± LIGHTWEIGHT U-NET GENERATOR
# ===========================================
def conv_block(x, filters, kernel_size=3):
    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    return x

def build_generator():
    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    c1 = conv_block(inp, 32)
    p1 = layers.MaxPooling2D()(c1)

    c2 = conv_block(p1, 64)
    p2 = layers.MaxPooling2D()(c2)

    c3 = conv_block(p2, 128)

    u2 = layers.UpSampling2D()(c3)
    concat2 = layers.Concatenate()([u2, c2])
    c4 = conv_block(concat2, 64)

    u1 = layers.UpSampling2D()(c4)
    concat1 = layers.Concatenate()([u1, c1])
    c5 = conv_block(concat1, 32)

    out = layers.Conv2D(3, 1, activation='sigmoid')(c5)
    return Model(inp, out, name="Lightweight_UNet_Generator")

# ===========================================
# üß± DISCRIMINATOR
# ===========================================
def build_discriminator():
    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    x = layers.Conv2D(16, 4, strides=2, padding='same')(inp)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(32, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(64, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Flatten()(x)
    out = layers.Dense(1, activation='sigmoid')(x)
    return Model(inp, out, name="Discriminator")

generator = build_generator()
discriminator = build_discriminator()

# ===========================================
# üéØ LOSSES
# ===========================================
vgg = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))
vgg.trainable = False
vgg_model = Model(vgg.input, vgg.get_layer('block3_conv3').output)

def perceptual_loss(y_true, y_pred):
    return tf.reduce_mean(tf.abs(vgg_model(y_true) - vgg_model(y_pred)))

def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

# ===========================================
# ‚öôÔ∏è OPTIMIZERS with Cosine Decay
# ===========================================
lr_schedule = CosineDecayRestarts(
    initial_learning_rate=initial_lr,
    first_decay_steps=5000,
    t_mul=2.0,
    m_mul=0.9,
    alpha=1e-6
)
gen_opt = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.5)
disc_opt = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.5)
bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)

# ===========================================
# üöÄ TRAINING STEP
# ===========================================
@tf.function
def train_step(noisy, clean):
    valid = tf.ones((tf.shape(noisy)[0], 1))
    fake = tf.zeros((tf.shape(noisy)[0], 1))

    with tf.GradientTape(persistent=True) as tape:
        generated = generator(noisy, training=True)
        real_output = discriminator(clean, training=True)
        fake_output = discriminator(generated, training=True)
        disc_loss = (bce(valid, real_output) + bce(fake, fake_output)) * 0.5

        gan_loss = bce(valid, fake_output)
        L1 = tf.reduce_mean(tf.abs(clean - generated))
        VGG_L = perceptual_loss(clean, generated)
        SSIM_L = ssim_loss(clean, generated)
        gen_total_loss = 0.7*L1 + 0.2*VGG_L + 0.1*SSIM_L + 0.001*gan_loss

    grad_gen = tape.gradient(gen_total_loss, generator.trainable_variables)
    grad_disc = tape.gradient(disc_loss, discriminator.trainable_variables)
    gen_opt.apply_gradients(zip(grad_gen, generator.trainable_variables))
    disc_opt.apply_gradients(zip(grad_disc, discriminator.trainable_variables))
    return gen_total_loss, disc_loss

# ===========================================
# üìä METRICS FUNCTION
# ===========================================
def evaluate_model(dataset):
    psnr_total, nmse_total, ssim_total, count = 0, 0, 0, 0
    for noisy, clean in dataset:
        gen = generator.predict(noisy, verbose=0)
        for i in range(len(gen)):
            clean_np = np.clip(clean[i].numpy(), 0, 1)
            gen_np = np.clip(gen[i], 0, 1)
            psnr_val = peak_signal_noise_ratio(clean_np, gen_np, data_range=1.0)
            ssim_val = structural_similarity(clean_np, gen_np, channel_axis=-1, data_range=1.0)
            nmse_val = np.mean((clean_np - gen_np)**2) / np.mean(clean_np**2)
            psnr_total += psnr_val
            ssim_total += ssim_val
            nmse_total += nmse_val
            count += 1
    return psnr_total/count, nmse_total/count, ssim_total/count

# ===========================================
# üèÉ‚Äç‚ôÄÔ∏è MAIN TRAINING LOOP
# ===========================================
for epoch in range(1, EPOCHS+1):
    g_loss_avg, d_loss_avg, batches = 0, 0, 0
    for noisy, clean in train_ds:
        g_loss, d_loss = train_step(noisy, clean)
        g_loss_avg += g_loss
        d_loss_avg += d_loss
        batches += 1
    g_loss_avg /= batches
    d_loss_avg /= batches

    val_psnr, val_nmse, val_ssim = evaluate_model(val_ds)
    print(f"Epoch {epoch}/{EPOCHS}")
    print(f"Gen Loss: {g_loss_avg:.4f}, Disc Loss: {d_loss_avg:.4f}")
    print(f"Validation PSNR: {val_psnr:.4f}, NMSE: {val_nmse:.6f}, SSIM: {val_ssim:.4f}")
    print("-"*60)

# ===========================================
# üß™ FINAL TEST EVALUATION
# ===========================================
test_psnr, test_nmse, test_ssim = evaluate_model(test_ds)
print("\n‚úÖ Final Test Results:")
print(f"PSNR: {test_psnr:.4f}, NMSE: {test_nmse:.6f}, SSIM: {test_ssim:.4f}")

# ===========================================
# üñºÔ∏è VISUALIZATION
# ===========================================
for noisy_imgs, clean_imgs in test_ds.take(1):
    denoised_imgs = generator(noisy_imgs, training=False)
    plt.figure(figsize=(12, 6))
    for i in range(3):
        plt.subplot(3,3,i*3+1)
        plt.title("Noisy")
        plt.imshow(noisy_imgs[i])
        plt.axis('off')
        plt.subplot(3,3,i*3+2)
        plt.title("Denoised")
        plt.imshow(denoised_imgs[i])
        plt.axis('off')
        plt.subplot(3,3,i*3+3)
        plt.title("Original")
        plt.imshow(clean_imgs[i])
        plt.axis('off')
    plt.show()

"""# **Noise 100**"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.applications import VGG19
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers.schedules import CosineDecayRestarts
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

# ===========================================
# ‚öôÔ∏è SETTINGS
# ===========================================
IMG_SIZE = 128
BATCH_SIZE = 8
EPOCHS = 20
NOISE_STD = 100 / 255.0  # scaled for [0,1]
initial_lr = 2e-4

# ===========================================
# üß† DATA PREPARATION (Oxford-IIIT Pet, 7349 images)
# ===========================================
full_ds = tfds.load('oxford_iiit_pet', split='train+test', with_info=False)


# 80‚Äì10‚Äì10 split
total_count = 7349
train_count = int(0.8 * total_count)
val_count = int(0.1 * total_count)
test_count = total_count - train_count - val_count

train_ds_raw = full_ds.take(train_count)
val_ds_raw = full_ds.skip(train_count).take(val_count)
test_ds_raw = full_ds.skip(train_count + val_count)

def preprocess(example):
    image = tf.image.resize(example['image'], [IMG_SIZE, IMG_SIZE])
    image = tf.cast(image, tf.float32) / 255.0
    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=NOISE_STD)
    noisy = tf.clip_by_value(image + noise, 0.0, 1.0)
    return noisy, image

train_ds = train_ds_raw.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
val_ds = val_ds_raw.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_ds = test_ds_raw.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# ===========================================
# üß± LIGHTWEIGHT U-NET GENERATOR
# ===========================================
def conv_block(x, filters, kernel_size=3):
    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    return x

def build_generator():
    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    c1 = conv_block(inp, 32)
    p1 = layers.MaxPooling2D()(c1)

    c2 = conv_block(p1, 64)
    p2 = layers.MaxPooling2D()(c2)

    c3 = conv_block(p2, 128)

    u2 = layers.UpSampling2D()(c3)
    concat2 = layers.Concatenate()([u2, c2])
    c4 = conv_block(concat2, 64)

    u1 = layers.UpSampling2D()(c4)
    concat1 = layers.Concatenate()([u1, c1])
    c5 = conv_block(concat1, 32)

    out = layers.Conv2D(3, 1, activation='sigmoid')(c5)
    return Model(inp, out, name="Lightweight_UNet_Generator")

# ===========================================
# üß± DISCRIMINATOR
# ===========================================
def build_discriminator():
    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    x = layers.Conv2D(16, 4, strides=2, padding='same')(inp)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(32, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(64, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.LeakyReLU(0.2)(x)
    x = layers.Flatten()(x)
    out = layers.Dense(1, activation='sigmoid')(x)
    return Model(inp, out, name="Discriminator")

generator = build_generator()
discriminator = build_discriminator()

# ===========================================
# üéØ LOSSES
# ===========================================
vgg = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))
vgg.trainable = False
vgg_model = Model(vgg.input, vgg.get_layer('block3_conv3').output)

def perceptual_loss(y_true, y_pred):
    return tf.reduce_mean(tf.abs(vgg_model(y_true) - vgg_model(y_pred)))

def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

# ===========================================
# ‚öôÔ∏è OPTIMIZERS with Cosine Decay
# ===========================================
lr_schedule = CosineDecayRestarts(
    initial_learning_rate=initial_lr,
    first_decay_steps=5000,
    t_mul=2.0,
    m_mul=0.9,
    alpha=1e-6
)
gen_opt = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.5)
disc_opt = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.5)
bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)

# ===========================================
# üöÄ TRAINING STEP
# ===========================================
@tf.function
def train_step(noisy, clean):
    valid = tf.ones((tf.shape(noisy)[0], 1))
    fake = tf.zeros((tf.shape(noisy)[0], 1))

    with tf.GradientTape(persistent=True) as tape:
        generated = generator(noisy, training=True)
        real_output = discriminator(clean, training=True)
        fake_output = discriminator(generated, training=True)
        disc_loss = (bce(valid, real_output) + bce(fake, fake_output)) * 0.5

        gan_loss = bce(valid, fake_output)
        L1 = tf.reduce_mean(tf.abs(clean - generated))
        VGG_L = perceptual_loss(clean, generated)
        SSIM_L = ssim_loss(clean, generated)
        gen_total_loss = 0.7*L1 + 0.2*VGG_L + 0.1*SSIM_L + 0.001*gan_loss

    grad_gen = tape.gradient(gen_total_loss, generator.trainable_variables)
    grad_disc = tape.gradient(disc_loss, discriminator.trainable_variables)
    gen_opt.apply_gradients(zip(grad_gen, generator.trainable_variables))
    disc_opt.apply_gradients(zip(grad_disc, discriminator.trainable_variables))
    return gen_total_loss, disc_loss

# ===========================================
# üìä METRICS FUNCTION
# ===========================================
def evaluate_model(dataset):
    psnr_total, nmse_total, ssim_total, count = 0, 0, 0, 0
    for noisy, clean in dataset:
        gen = generator.predict(noisy, verbose=0)
        for i in range(len(gen)):
            clean_np = np.clip(clean[i].numpy(), 0, 1)
            gen_np = np.clip(gen[i], 0, 1)
            psnr_val = peak_signal_noise_ratio(clean_np, gen_np, data_range=1.0)
            ssim_val = structural_similarity(clean_np, gen_np, channel_axis=-1, data_range=1.0)
            nmse_val = np.mean((clean_np - gen_np)**2) / np.mean(clean_np**2)
            psnr_total += psnr_val
            ssim_total += ssim_val
            nmse_total += nmse_val
            count += 1
    return psnr_total/count, nmse_total/count, ssim_total/count

# ===========================================
# üèÉ‚Äç‚ôÄÔ∏è MAIN TRAINING LOOP
# ===========================================
for epoch in range(1, EPOCHS+1):
    g_loss_avg, d_loss_avg, batches = 0, 0, 0
    for noisy, clean in train_ds:
        g_loss, d_loss = train_step(noisy, clean)
        g_loss_avg += g_loss
        d_loss_avg += d_loss
        batches += 1
    g_loss_avg /= batches
    d_loss_avg /= batches

    val_psnr, val_nmse, val_ssim = evaluate_model(val_ds)
    print(f"Epoch {epoch}/{EPOCHS}")
    print(f"Gen Loss: {g_loss_avg:.4f}, Disc Loss: {d_loss_avg:.4f}")
    print(f"Validation PSNR: {val_psnr:.4f}, NMSE: {val_nmse:.6f}, SSIM: {val_ssim:.4f}")
    print("-"*60)

# ===========================================
# üß™ FINAL TEST EVALUATION
# ===========================================
test_psnr, test_nmse, test_ssim = evaluate_model(test_ds)
print("\n‚úÖ Final Test Results:")
print(f"PSNR: {test_psnr:.4f}, NMSE: {test_nmse:.6f}, SSIM: {test_ssim:.4f}")

# ===========================================
# üñºÔ∏è VISUALIZATION
# ===========================================
for noisy_imgs, clean_imgs in test_ds.take(1):
    denoised_imgs = generator(noisy_imgs, training=False)
    plt.figure(figsize=(12, 6))
    for i in range(3):
        plt.subplot(3,3,i*3+1)
        plt.title("Noisy")
        plt.imshow(noisy_imgs[i])
        plt.axis('off')
        plt.subplot(3,3,i*3+2)
        plt.title("Denoised")
        plt.imshow(denoised_imgs[i])
        plt.axis('off')
        plt.subplot(3,3,i*3+3)
        plt.title("Original")
        plt.imshow(clean_imgs[i])
        plt.axis('off')
    plt.show()
